{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae784af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95781d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maatool.data.feats_itdataset_v2 import FeatsIterableDatasetV2\n",
    "from maatool.models.transformer import TransformerWithSinPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6420220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55476934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "def configure_logging(log_level):\n",
    "    handlers =  {\n",
    "            \"maa\": {\n",
    "                \"class\": \"logging.StreamHandler\",\n",
    "                \"formatter\": \"maa_basic\",\n",
    "                \"stream\": \"ext://sys.stdout\",\n",
    "            }\n",
    "    }\n",
    "    CONFIG = {\n",
    "        \"version\": 1,\n",
    "        \"disable_existing_loggers\": False,\n",
    "        \"formatters\": {\"maa_basic\": {\"format\": '%(asctime)s %(name)s %(pathname)s:%(lineno)d - %(levelname)s - %(message)s'}},\n",
    "        \"handlers\": handlers,\n",
    "        \"loggers\": {\"maa\": {\"handlers\": handlers.keys(), \"level\": log_level}},\n",
    "        \"root\": {\"handlers\": handlers.keys(), \"level\": log_level}\n",
    "    }\n",
    "    logging.config.dictConfig(CONFIG)\n",
    "configure_logging(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d674be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfcf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61021f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_tgt(prev_tgt, hyp_logprobs, logits, topk=4):\n",
    "    \"\"\"\n",
    "    prev_tgt - (T, N_hyp)\n",
    "    hyp_logprobs - (N_hyp, )\n",
    "    logits - (N_hyp, C)\n",
    "    \"\"\"\n",
    "    assert len(prev_tgt.shape) == 2, f\"{prev_tgt.shape=}\"\n",
    "    assert len(hyp_logprobs.shape) == 1, f\"{hyp_logprobs.shape=}\"\n",
    "    assert len(logits.shape) == 2, f\"{logits.shape=}\"\n",
    "    assert prev_tgt.shape[1] == hyp_logprobs.shape[0] == logits.shape[0], (\n",
    "        f\"{prev_tgt.shape=} {hyp_logprobs.shape=} {logits.shape=}\"\n",
    "    )\n",
    "        \n",
    "    nt_topk_logits, nt_topk_idx = logits.topk(k=topk, axis=-1)\n",
    "    #print(\"nt_topk_idx\", nt_topk_idx, nt_topk_idx.shape)\n",
    "    # (N, K)\n",
    "    next_tokens = nt_topk_idx.T.reshape(1, -1)\n",
    "    #print(\"next_tokens\", next_tokens, next_tokens.shape)\n",
    "    # (1, N*(repeat k times)) \n",
    "    # (T, N*(repeat k times))  \n",
    "    new_hyp_tgt = torch.concatenate([prev_tgt.repeat(1, topk), next_tokens], axis=0)\n",
    "    #print(f\"{new_hyp_tgt=}\", new_hyp_tgt.shape)\n",
    "    # (T+1, N*(repeat k times))\n",
    "    new_scores = nt_topk_logits.T.reshape(-1)\n",
    "    # N*(repeat k times)\n",
    "    prew_scores = hyp_logprobs.repeat(topk)\n",
    "    #print(\"prew_scores\", prew_scores)\n",
    "    # N*(repeat k times)\n",
    "    new_hyp_logprob = prew_scores + new_scores\n",
    "    #print(\"new_hyp_logprob\", new_hyp_logprob)\n",
    "    new_hyp_logprob, idx = new_hyp_logprob.topk(k=topk)\n",
    "    #print(idx)\n",
    "    new_hyps = new_hyp_tgt[:, idx]\n",
    "    #print(\"new_hyps\", new_hyps, new_hyp_logprob)\n",
    "    # (T+1, N*k), (N,)\n",
    "    return new_hyps, new_hyp_logprob\n",
    "    \n",
    "\n",
    "    \n",
    "tgt, logits = get_new_tgt(torch.LongTensor([[1,]]), torch.tensor([-1.]), torch.tensor([[-3, -4, -7, -2, -5]]))\n",
    "print(\">>>>\\n\", tgt, logits)\n",
    "get_new_tgt(tgt, logits, torch.tensor([[100,    110,  200], \n",
    "                                       [100,    110,  200], \n",
    "                                       [100,    110,  200], \n",
    "                                       [100,    110,  200]]), topk=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_ready_tgt(tgt, logprobs, eos_id=2):\n",
    "    \"\"\"\n",
    "    tgt - (T, N)\n",
    "    logprobs - (N,)\n",
    "    \"\"\"\n",
    "    assert tgt.shape[1] == logprobs.shape[0], (\n",
    "        f\"{tgt.shape=} {logprobs.shape=}\"\n",
    "    )\n",
    "    \n",
    "    is_end_mask = ((tgt == eos_id).sum(axis=0) > 0)\n",
    "    # (N,)\n",
    "    #print(is_end_mask)\n",
    "    ready_tgt = tgt[:, is_end_mask]\n",
    "    ready_logprobs = logprobs[is_end_mask]\n",
    "    \n",
    "    ready_list = [(l.cpu().item(), t.cpu().tolist()) for l, t in zip(ready_logprobs, ready_tgt.T)]\n",
    "\n",
    "    not_ready_tgt = tgt[:, ~is_end_mask]\n",
    "    not_ready_logprobs = logprobs[~is_end_mask]\n",
    "    assert not_ready_tgt.shape[1] == not_ready_logprobs.shape[0], (\n",
    "        f\"{not_ready_tgt.shape[1]=} {not_ready_logprobs.shape[0]=}\"\n",
    "    )\n",
    "    return ready_list, not_ready_tgt, not_ready_logprobs\n",
    "\n",
    "\n",
    "sep_ready_tgt(torch.LongTensor([[1, 1], [2, 3]]), torch.tensor([-1., -3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5336cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    if seed < 0:\n",
    "        seed = seed_from_time()\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "set_random_seed(42)\n",
    "\n",
    "class SwipeTransformerRecognizer(pl.LightningModule):\n",
    "    def __init__(self, backbone, learning_rate=1e-4, speed=42):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['backbone'])\n",
    "        self.backbone = backbone\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=0, reduction='mean')\n",
    "        set_random_seed(speed)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        return self.backbone(**kwargs)\n",
    "    \n",
    "    def get_loss(self, batch):\n",
    "        # batch - (Time, Batch, ...)\n",
    "        feats = batch['feats']\n",
    "        # (Time, Batch, num_feats)\n",
    "        tgt = batch['targets'][:-1]\n",
    "        tgt_key_padding_mask = batch['tgt_key_padding_mask'][:, 1:] \n",
    "        # (Batch, Seq-1)\n",
    "        logits = self.backbone(feats=feats, \n",
    "                               tgt=tgt, \n",
    "                               src_key_padding_mask=batch['src_key_padding_mask'], \n",
    "                               tgt_key_padding_mask=tgt_key_padding_mask) \n",
    "        # (Seq-1, Batch, C)\n",
    "        S, N, C = logits.shape\n",
    "        targets = batch['targets'][1:]\n",
    "        # (Seq-1, Batch)\n",
    "        # print(\"loss \", logits.shape, targets.shape)\n",
    "        loss = self.ce_loss(logits.view(-1, C), targets.reshape(-1))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True,  batch_size=len(batch['uids']))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('valid_loss', loss, on_step=True,  batch_size=len(batch['uids']))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('test_loss', loss,  batch_size=len(batch['uids']))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
    "        return parser\n",
    "    \n",
    "    def predict_topk(self, dl, tokenizer, topk=4, bos_id=1, eos_id=2, max_out_len=26):\n",
    "        utt2word= defaultdict(list)\n",
    "        utt2logs = defaultdict(list)\n",
    "        pbar = tqdm(dl)\n",
    "        for batch in pbar:\n",
    "            memory = self.backbone.forward_encoder(batch['feats'], \n",
    "                                              src_key_padding_mask=batch['src_key_padding_mask'])\n",
    "            assert memory.shape[1] == 1, f\"{memory.shape=}\"\n",
    "            # (SrcTime, Batch, E)\n",
    "            tgt = torch.full(size=(1, 1), \n",
    "                             fill_value=bos_id, \n",
    "                             dtype=torch.long, \n",
    "                             device=memory.device)\n",
    "            hyp_logprobs = torch.zeros((1), device=memory.device)\n",
    "            tgt_ready = []\n",
    "            mkpm = batch['src_key_padding_mask']\n",
    "            for l in range(max_out_len):\n",
    "                #print(f\"{tgt.shape=}\")\n",
    "                tgt_logits = self.backbone.forward_decoder(tgt, \n",
    "                                                    memory.repeat(1, tgt.shape[1], 1), \n",
    "                                                    memory_key_padding_mask=mkpm.repeat((tgt.shape[1], 1)))\n",
    "                tgt_logits = tgt_logits.log_softmax(dim=-1)\n",
    "                \n",
    "                new_tgt, logprobs = get_new_tgt(tgt, hyp_logprobs, tgt_logits[-1], topk=topk)\n",
    "                ready, tgt, hyp_logprobs = sep_ready_tgt(new_tgt, logprobs)\n",
    "                tgt_ready.extend(ready)\n",
    "                if len(tgt_ready) >= topk:\n",
    "                    break\n",
    "                \n",
    "            uid = batch['uids'][0]\n",
    "            if len(tgt_ready) == 0:\n",
    "                logging.warning(f\"tgt_ready is 0 for {uid}. {tgt.shape=}. Use all hyps as ready hyps\")\n",
    "                tgt_ready = [(l.cpu().item(), t.cpu().tolist()) for l, t in zip(hyp_logprobs, tgt.T)]\n",
    "                \n",
    "            out_indices = []\n",
    "            for logprob, indices in sorted(tgt_ready, reverse=True):\n",
    "                joined = tokenizer.decode(indices) #.split()[0]\n",
    "                utt2word[uid].append(joined)\n",
    "                utt2logs[uid].append(logprob)\n",
    "            d = '|'+'|'.join(utt2word[uid]) + \"|\"\n",
    "            pbar.set_description(f\"{d}\\t\".ljust(40, '='), refresh=False)\n",
    "        return utt2word, utt2logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([1,2,3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e92a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 nt_topk_logits, nt_topk_idx = tgt_logits.topk(k=topk, axis=-1)\n",
    "#                 next_tokens = nt_topk_idx[-1:] \n",
    "#                 # (1, N, K)\n",
    "#                 next_tokens = next_tokens.transpose(1, 2).reshape(1, -1)\n",
    "#                 # (1, N*(repeat k times)) \n",
    "#                 new_tgt = tgt.repeat(1, topk)\n",
    "#                 # (T, N*(repeat k times))  \n",
    "#                 new_tgt = torch.concatenate([new_tgt, next_tokens], axis=0)\n",
    "#                 #print(f\"{new_tgt.shape}\")\n",
    "#                 # (T, N_new)\n",
    "#                 new_scores = nt_topk_logits[-1].T.reshape(-1)\n",
    "#                 prew_scores = tgt_logprobs.repeat(topk)\n",
    "#                 tgt_logprobs = prew_scores + new_scores\n",
    "                # (N,)\n",
    "                \n",
    "#                 is_end_mask = ((new_tgt == eos_id).sum(axis=0) > 0)\n",
    "#                 # (N,)\n",
    "#                 #print(is_end_mask)\n",
    "#                 new_ready = new_tgt[:, is_end_mask]\n",
    "#                 new_ready_logprobs = tgt_logprobs[is_end_mask]\n",
    "#                 tgt_ready.extend([(l.cpu(), t.cpu()) for t, l in zip(new_ready.T, new_ready_logprobs)])\n",
    "                \n",
    "#                 #print(is_end)\n",
    "#                 if len(tgt_ready) >= topk:\n",
    "#                     break\n",
    "                \n",
    "#                 tgt = new_tgt[:, ~is_end_mask]\n",
    "#                 tgt_logprobs = tgt_logprobs[~is_end_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b885d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerWithSinPos(feats_dim=37, num_tokens=500)\n",
    "pl_module = SwipeTransformerRecognizer.load_from_checkpoint('exp/models/transformer_sc/lightning_logs/version_50424998/checkpoints/last.ckpt',backbone=model, map_location='cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028788f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2words, utt2logs = pl_module.predict_topk(val_dataloader, tokenizer=tokenizer, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b718b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(valid_ref_u2w, {k:v[0] for k, v in utt2words.items()})\n",
    "# topk2 total=10000 corr=8429 err=1571, accuracy: 0.8429\n",
    "# topk5 total=10000 corr=8434 err=1566, accuracy: 0.8434\n",
    "# topk10 total=10000 corr=8388 err=1612, accuracy: 0.8388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/voc.txt') as f:\n",
    "    vocab = frozenset(s for s in map(str.strip, f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = {}\n",
    "for k, v in utt2words.items():\n",
    "    corr_w = None\n",
    "    for w in v:\n",
    "        if w in vocab:\n",
    "            corr_w = w\n",
    "            break\n",
    "    if corr_w is None: \n",
    "        logging.warning(f\"{k=} doesn't have any vocab hyp. {v=}\")\n",
    "        corr_w = '-'\n",
    "    lv[k] = corr_w\n",
    "accuracy(valid_ref_u2w, lv)\n",
    "# topk10 total=10000 corr=8542 err=1458, accuracy: 0.8542\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds =  FeatsIterableDatasetV2([f\"ark:data_feats/test/feats.ark\"], shuffle=False, \n",
    "                                 bos_id=1, \n",
    "                                 eos_id=2, \n",
    "                                 batch_first=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=1, collate_fn=test_ds.collate_pad)\n",
    "#test_u2w = predict(pl_module.backbone, test_dataloader)\n",
    "test_u2w, test_u2l = pl_module.predict_topk(test_dataloader, tokenizer=tokenizer, topk=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5cd6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def limit_vocab(u2w, vocab=vocab):\n",
    "    lv = {}\n",
    "    for k, v in u2w.items():\n",
    "        corr_w = []\n",
    "        for w in v:\n",
    "            if w in vocab:\n",
    "                corr_w.append(w)\n",
    "        if len(corr_w) == 0: \n",
    "            logging.warning(f\"{k=} doesn't have any vocab hyp. {v=}\")\n",
    "            corr_w = ['-']\n",
    "        lv[k] = corr_w\n",
    "    return lv\n",
    "test_lv = limit_vocab(test_u2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7350cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, k = torch.topk(x, 2, axis=-1)\n",
    "print(k)\n",
    "\n",
    "k[1:, :, :].transpose(1,2).reshape(1, 2*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concatenate([x, k], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ecc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ./exp/bpe500/model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8439ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = FeatsIterableDatasetV2([f\"ark:data_feats/valid/feats.ark\"], \n",
    "                             targets_rspecifier='ark:exp/bpe500/valid-text.int', \n",
    "                                shuffle=False,\n",
    "                               bos_id=1, \n",
    "                               eos_id=2,\n",
    "                               batch_first=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=1, collate_fn=val_ds.collate_pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b20486",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_feats/valid/text') as f:\n",
    "    valid_ref_u2w = {u:w for u, w in   map(str.split, f.readlines())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for b in tqdm(val_dataloader):\n",
    "    pass\n",
    "print(\"Done\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b['feats'].shape, b['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa615a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FeatsIterableDatasetV2([f\"ark:{f}\" for f in sorted(glob(\"data_feats/train/feats.*.ark\"))],\n",
    "                                  targets_rspecifier='ark:exp/bpe500/train-text.int.ark', \n",
    "                                  shuffle=True,\n",
    "                                  bos_id=1, \n",
    "                                  eos_id=2, \n",
    "                                 batch_first=False)\n",
    "\n",
    "#train_ds = val_ds\n",
    "\n",
    "#\n",
    "# 35799.91it/s - txt format\n",
    "# vs\n",
    "# 136753.6it/s - ark format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1611505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=24, collate_fn=train_ds.collate_pad, \n",
    "                                                num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=6, log_every_n_steps=400, reload_dataloaders_every_n_epochs=1,\n",
    "                    default_root_dir='exp/models/transformer_sc',\n",
    "                    callbacks=[pl.callbacks.TQDMProgressBar(refresh_rate=100),\n",
    "                              pl.callbacks.ModelCheckpoint(every_n_train_steps=20000,\n",
    "                                                          save_last=True)],\n",
    "                    accumulate_grad_batches=4, \n",
    "                    check_val_every_n_epoch=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerWithSinPos(feats_dim=37, num_tokens=500)\n",
    "pl_module = SwipeTransformerRecognizer(backbone=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d6e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3100b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    loss = pl_module.get_loss(b)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ac9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50330eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pl_module.eval()\n",
    "    feats = b['feats']\n",
    "    # (Batch, Time, num_feats)\n",
    "    tgt = b['targets'][:, :-1]\n",
    "    print(feats.shape, b['targets'].shape, tgt.shape)\n",
    "    tgt_key_padding_mask = b['tgt_key_padding_mask'][:, :-1] \n",
    "    #tgt_key_padding_mask = b['tgt_key_padding_mask'][:, :-1]\n",
    "    # (Batch, Seq-1)\n",
    "    logits = pl_module.backbone(feats=feats, \n",
    "                           tgt=tgt, \n",
    "                           src_key_padding_mask=b['src_key_padding_mask'], \n",
    "                           tgt_key_padding_mask=tgt_key_padding_mask) \n",
    "    # (Seq-1, Batch, C)\n",
    "    S, N, C = logits.shape\n",
    "    targets = b['targets'][:, 1:].T\n",
    "    #tgt_key_padding_mask \n",
    "    # (Seq-1, Batch)\n",
    "    print(\"loss \", logits.shape, targets.shape)\n",
    "    loss = pl_module.ce_loss(logits.view(-1, C), targets.reshape(-1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pl_module.eval()\n",
    "    l = []\n",
    "    t = []\n",
    "    for i in range(b['feats'].shape[0]):\n",
    "        feats = b['feats'][i:i+1]\n",
    "        # (Batch, Time, num_feats)\n",
    "        tgt = b['targets'][i:i+1, :-1]\n",
    "        print(feats.shape, b['targets'].shape, tgt.shape)\n",
    "        tgt_key_padding_mask = b['tgt_key_padding_mask'][i:i+1, :-1] \n",
    "        #tgt_key_padding_mask = b['tgt_key_padding_mask'][:, :-1]\n",
    "        # (Batch, Seq-1)\n",
    "        logits = pl_module.backbone(feats=feats, \n",
    "                               tgt=tgt, \n",
    "                               src_key_padding_mask=b['src_key_padding_mask'][i:i+1], \n",
    "                               tgt_key_padding_mask=tgt_key_padding_mask) \n",
    "        # (Seq-1, Batch, C)\n",
    "        S, N, C = logits.shape\n",
    "        targets = b['targets'][i:i+1, 1:].T\n",
    "        #tgt_key_padding_mask \n",
    "        # (Seq-1, Batch)\n",
    "        print(\"loss \", logits.shape, targets.shape)\n",
    "        l.append(logits.view(-1, C))\n",
    "        t.append(targets.reshape(-1))\n",
    "    loss = pl_module.ce_loss(torch.concatenate(l), torch.concatenate(t))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt, tt = torch.concatenate(l), torch.concatenate(t)\n",
    "print(lt.shape, tt.shape)\n",
    "lt = lt[tt!=0]\n",
    "tt = tt[tt!=0]\n",
    "print(lt.shape, tt.shape)\n",
    "torch.nn.CrossEntropyLoss()(lt, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.fit(pl_module, val_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(pl_module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fba3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = trainer.test(pl_module, train_dataloader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efdd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.test(pl_module, val_dataloader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e603f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerWithSinPos(feats_dim=37, num_tokens=500)\n",
    "pl_module = SwipeTransformerRecognizer.load_from_checkpoint('exp/models/transformer_sc/lightning_logs/version_50424998/checkpoints/last.ckpt',backbone=model, map_location='cpu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818bf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=2, log_every_n_steps=400, reload_dataloaders_every_n_epochs=1,\n",
    "                    default_root_dir='exp/models/transformer_sc',\n",
    "                    callbacks=[pl.callbacks.TQDMProgressBar(refresh_rate=100),\n",
    "                              pl.callbacks.ModelCheckpoint(every_n_train_steps=10000,\n",
    "                                                          save_last=True)],\n",
    "                    accumulate_grad_batches=4, \n",
    "                    check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c80f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.test(pl_module, val_dataloader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(pl_module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.test(pl_module, val_dataloader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19861f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = torch.LongTensor([3, 4, 2, 6, 5, 1, 3, 2, 4, 7])\n",
    "M = torch.arange(20) < L[:, None]\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1e72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e82d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spm.SentencePieceProcessor('exp/bpe500/model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3728616",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([[10, 11, 12], [12, 13, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(backbone, dl, bos_id=1, eos_id=2, max_out_len=10):\n",
    "\n",
    "    utt2word={}\n",
    "    pbar = tqdm(dl)\n",
    "    for batch in pbar:\n",
    "        src_embs = backbone.input_ff(batch['feats'])\n",
    "        # (S, B, E)\n",
    "        src_embs = backbone.positional_encoding(src_embs)\n",
    "        memory = backbone.transformer.encoder(src_embs, src_key_padding_mask=batch['src_key_padding_mask'])\n",
    "        # (Time, Batch, E)\n",
    "        tgt = torch.full(size=(1, memory.shape[1]), fill_value=bos_id, dtype=torch.long, device=memory.device)\n",
    "        for _ in range(max_out_len):\n",
    "            tgt_embs = backbone.tgt_embedding(tgt) * math.sqrt(backbone.d_model)\n",
    "            tgt_embs = backbone.positional_encoding(tgt_embs)\n",
    "            mask = pl_module.backbone.transformer.generate_square_subsequent_mask(tgt.shape[0], device=tgt.device)\n",
    "            #print(tgt_embs.shape, memory.shape)\n",
    "            next_tokens = backbone.transformer.decoder(tgt_embs, memory, tgt_mask=mask)\n",
    "            next_tokens = backbone.head(next_tokens).argmax(dim=-1)\n",
    "\n",
    "            #print(tgt.shape, next_tokens.shape)\n",
    "            tgt = torch.concatenate([tgt, next_tokens[-1:]], axis=0)\n",
    "            #print(tgt)\n",
    "            is_end = ((tgt == eos_id).sum(axis=0) > 0).all()\n",
    "            #print(is_end)\n",
    "            if is_end:\n",
    "                break\n",
    "\n",
    "        for uid, indices in zip(batch['uids'], tgt.T):\n",
    "            out_indices = []\n",
    "            for i in indices.tolist():\n",
    "                out_indices.append(i)\n",
    "                if i == eos_id:\n",
    "                    break\n",
    "\n",
    "            # torch.unique_consecutive(indices, dim=-1).tolist()\n",
    "            #print(indices)\n",
    "            joined = tokenizer.decode(out_indices).split()[0]\n",
    "            pbar.set_description(f\"{joined}\", refresh=False)\n",
    "            utt2word[uid] = joined\n",
    "    return utt2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56972efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_v2(backbone: TransformerWithSinPos, dl, bos_id=1, eos_id=2, max_out_len=10):\n",
    "\n",
    "    utt2word={}\n",
    "    pbar = tqdm(dl)\n",
    "    for batch in pbar:\n",
    "        memory = backbone.forward_encoder(batch['feats'], \n",
    "                                          src_key_padding_mask=batch['src_key_padding_mask'])\n",
    "        # (SrcTime, Batch, E)\n",
    "        tgt = torch.full(size=(1, memory.shape[1]), \n",
    "                         fill_value=bos_id, \n",
    "                         dtype=torch.long, \n",
    "                         device=memory.device)\n",
    "        for _ in range(max_out_len):\n",
    "            tgt_embs = backbone.forward_decoder(tgt, \n",
    "                                                memory, \n",
    "                                                memory_key_padding_mask=batch['src_key_padding_mask'])\n",
    "\n",
    "            next_tokens = tgt_embs.argmax(dim=-1)\n",
    "\n",
    "            #print(tgt.shape, next_tokens.shape)\n",
    "            tgt = torch.concatenate([tgt, next_tokens[-1:]], axis=0)\n",
    "            #print(tgt)\n",
    "            is_end = ((tgt == eos_id).sum(axis=0) > 0).all()\n",
    "            #print(is_end)\n",
    "            if is_end:\n",
    "                break\n",
    "\n",
    "        for uid, indices in zip(batch['uids'], tgt.T):\n",
    "            out_indices = []\n",
    "            for i in indices.tolist():\n",
    "                out_indices.append(i)\n",
    "                if i == eos_id:\n",
    "                    break\n",
    "\n",
    "            # torch.unique_consecutive(indices, dim=-1).tolist()\n",
    "            #print(indices)\n",
    "            joined = tokenizer.decode(out_indices).split()[0]\n",
    "            pbar.set_description(f\"{joined}\", refresh=False)\n",
    "            utt2word[uid] = joined\n",
    "    return utt2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d1099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_u2w = predict_v2(pl_module.backbone, val_dataloader)\n",
    "with open('data_feats/valid/text') as f:\n",
    "    valid_ref_u2w = {u:w for u, w in   map(str.split, f.readlines())}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ref_u2w, hyp_u2w):\n",
    "    corr = 0\n",
    "    err = 0\n",
    "    total = len(ref_u2w)\n",
    "    for u, ref in tqdm(ref_u2w.items()):\n",
    "        hyp = hyp_u2w[u].strip('-')\n",
    "        if ref != hyp:\n",
    "            print(ref, hyp)\n",
    "            err +=1\n",
    "        else:\n",
    "            corr +=1\n",
    "    a = corr/total\n",
    "    print(f\"{total=} {corr=} {err=}, accuracy: {a}\")\n",
    "    return a\n",
    "#accuracy(valid_ref_u2w, valid_u2w)\n",
    "# total=10000 corr=8227 err=1773, accuracy: 0.8227\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46ae19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds =  FeatsIterableDatasetV2([f\"ark:data_feats/test/feats.ark\"], shuffle=False, \n",
    "                                 bos_id=1, \n",
    "                                  eos_id=2, \n",
    "                                 batch_first=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=1, collate_fn=test_ds.collate_pad)\n",
    "test_u2w = predict(pl_module.backbone, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b04742",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_u2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247396a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result = pd.read_csv('exp/models/ctc_trans/lightning_logs/version_50422251/test_submit.v1.csv', sep=',', names=['main', 'second', 'third', 'trash'])\n",
    "baseline_result['uid'] = [f'test-{i}' for i in range(len(baseline_result))]\n",
    "baseline_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d399dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result['predict'] = baseline_result.uid.apply(lambda x: test_u2w[x].strip('-'))\n",
    "baseline_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ec7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result[baseline_result['main']!= baseline_result['predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, row in baseline_result.iterrows():\n",
    "    old_main = row['main']\n",
    "    new_main = row['predict']\n",
    "    if new_main != old_main:\n",
    "        new_s = old_main\n",
    "        new_th = row['second']\n",
    "        new_tr = row['third']\n",
    "    else:\n",
    "        new_s = row['second']\n",
    "        new_th = row['third']\n",
    "        new_tr = row['trash']\n",
    "    rows.append({\"main\": new_main,\n",
    "                \"second\": new_s,\n",
    "                \"third\": new_th,\n",
    "                \"trash\": new_tr})\n",
    "        \n",
    "submission = pd.DataFrame(rows)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"exp/models/transformer_sc/lightning_logs//version_50432204/test_submit.v3.csv\", \n",
    "                  sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83daa8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a1b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7168f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result['predict'] = baseline_result.uid.apply(lambda u: test_lv[u])\n",
    "baseline_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, row in baseline_result.iterrows():\n",
    "    ps = row['predict']\n",
    "    for p in [row['main'], row['second'], row['third'], row['trash']]:\n",
    "        if p not in ps:\n",
    "            ps.append(p)\n",
    "    rows.append(ps[:4])\n",
    "        \n",
    "submission = pd.DataFrame(rows, columns=['main', 'second', 'third', 'trash'])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"exp/models/transformer_sc/lightning_logs/version_50424998/test_submit.v4.csv\", \n",
    "                  sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb125b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = pd.read_csv('exp/models/transformer_sc/lightning_logs/version_50424998/test_submit.v5.csv', sep=',', names=['main', 'second', 'third', 'trash'])\n",
    "s5['uid'] = [f'test-{i}' for i in range(len(s5))]\n",
    "s5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1694a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerWithSinPos(feats_dim=37, num_tokens=500)\n",
    "pl_module = SwipeTransformerRecognizer.load_from_checkpoint('exp/models/transformer_sc/lightning_logs/version_50424998/checkpoints/last.ckpt',backbone=model, map_location='cpu' )\n",
    "\n",
    "val_ds = FeatsIterableDatasetV2([f\"ark:data_feats/valid/feats.ark\"], \n",
    "                                 targets_rspecifier='ark:exp/bpe500/valid-text.int', \n",
    "                                 shuffle=False,\n",
    "                                 bos_id=1, \n",
    "                                 eos_id=2,\n",
    "                                 batch_first=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=1, collate_fn=val_ds.collate_pad)\n",
    "utt2words, utt2logs = pl_module.predict_topk(val_dataloader, tokenizer=tokenizer, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = {}\n",
    "for k, v in utt2words.items():\n",
    "    corr_w = None\n",
    "    for w in v:\n",
    "        if w in vocab:\n",
    "            corr_w = w\n",
    "            break\n",
    "    if corr_w is None: \n",
    "        logging.warning(f\"{k=} doesn't have any vocab hyp. {v=}\")\n",
    "        corr_w = '-'\n",
    "    lv[k] = corr_w\n",
    "accuracy(valid_ref_u2w, lv)\n",
    "# topk10 total=10000 corr=8542 err=1458, accuracy: 0.8542"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
