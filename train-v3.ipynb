{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae784af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95781d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch import nn\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from torchaudio import transforms as T\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maatool.data.feats_itdataset_v2 import FeatsIterableDatasetV2\n",
    "from maatool.models.transformer import TransformerWithSinPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6420220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55476934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "def configure_logging(log_level):\n",
    "    handlers =  {\n",
    "            \"maa\": {\n",
    "                \"class\": \"logging.StreamHandler\",\n",
    "                \"formatter\": \"maa_basic\",\n",
    "                \"stream\": \"ext://sys.stdout\",\n",
    "            }\n",
    "    }\n",
    "    CONFIG = {\n",
    "        \"version\": 1,\n",
    "        \"disable_existing_loggers\": False,\n",
    "        \"formatters\": {\"maa_basic\": {\"format\": '%(asctime)s %(name)s %(pathname)s:%(lineno)d - %(levelname)s - %(message)s'}},\n",
    "        \"handlers\": handlers,\n",
    "        \"loggers\": {\"maa\": {\"handlers\": handlers.keys(), \"level\": log_level}},\n",
    "        \"root\": {\"handlers\": handlers.keys(), \"level\": log_level}\n",
    "    }\n",
    "    logging.config.dictConfig(CONFIG)\n",
    "configure_logging(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d674be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.is_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfcf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61021f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_tgt(prev_tgt, hyp_logprobs, logits, topk=4):\n",
    "    \"\"\"\n",
    "    prev_tgt - (T, N_hyp)\n",
    "    hyp_logprobs - (N_hyp, )\n",
    "    logits - (N_hyp, C)\n",
    "    \"\"\"\n",
    "    assert len(prev_tgt.shape) == 2, f\"{prev_tgt.shape=}\"\n",
    "    assert len(hyp_logprobs.shape) == 1, f\"{hyp_logprobs.shape=}\"\n",
    "    assert len(logits.shape) == 2, f\"{logits.shape=}\"\n",
    "    assert prev_tgt.shape[1] == hyp_logprobs.shape[0] == logits.shape[0], (\n",
    "        f\"{prev_tgt.shape=} {hyp_logprobs.shape=} {logits.shape=}\"\n",
    "    )\n",
    "        \n",
    "    nt_topk_logits, nt_topk_idx = logits.topk(k=topk, axis=-1)\n",
    "    #print(\"nt_topk_idx\", nt_topk_idx, nt_topk_idx.shape)\n",
    "    # (N, K)\n",
    "    next_tokens = nt_topk_idx.T.reshape(1, -1)\n",
    "    #print(\"next_tokens\", next_tokens, next_tokens.shape)\n",
    "    # (1, N*(repeat k times)) \n",
    "    # (T, N*(repeat k times))  \n",
    "    new_hyp_tgt = torch.concatenate([prev_tgt.repeat(1, topk), next_tokens], axis=0)\n",
    "    #print(f\"{new_hyp_tgt=}\", new_hyp_tgt.shape)\n",
    "    # (T+1, N*(repeat k times))\n",
    "    new_scores = nt_topk_logits.T.reshape(-1)\n",
    "    # N*(repeat k times)\n",
    "    prew_scores = hyp_logprobs.repeat(topk)\n",
    "    #print(\"prew_scores\", prew_scores)\n",
    "    # N*(repeat k times)\n",
    "    new_hyp_logprob = prew_scores + new_scores\n",
    "    #print(\"new_hyp_logprob\", new_hyp_logprob)\n",
    "    new_hyp_logprob, idx = new_hyp_logprob.topk(k=topk)\n",
    "    #print(idx)\n",
    "    new_hyps = new_hyp_tgt[:, idx]\n",
    "    #print(\"new_hyps\", new_hyps, new_hyp_logprob)\n",
    "    # (T+1, N*k), (N,)\n",
    "    return new_hyps, new_hyp_logprob\n",
    "    \n",
    "\n",
    "    \n",
    "tgt, logits = get_new_tgt(torch.LongTensor([[1,]]), torch.tensor([-1.]), torch.tensor([[-3, -4, -7, -2, -5]]))\n",
    "print(\">>>>\\n\", tgt, logits)\n",
    "get_new_tgt(tgt, logits, torch.tensor([[100,    110,  200], \n",
    "                                       [100,    110,  200], \n",
    "                                       [100,    110,  200], \n",
    "                                       [100,    110,  200]]), topk=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_ready_tgt(tgt, logprobs, eos_id=2):\n",
    "    \"\"\"\n",
    "    tgt - (T, N)\n",
    "    logprobs - (N,)\n",
    "    \"\"\"\n",
    "    assert tgt.shape[1] == logprobs.shape[0], (\n",
    "        f\"{tgt.shape=} {logprobs.shape=}\"\n",
    "    )\n",
    "    \n",
    "    is_end_mask = ((tgt == eos_id).sum(axis=0) > 0)\n",
    "    # (N,)\n",
    "    #print(is_end_mask)\n",
    "    ready_tgt = tgt[:, is_end_mask]\n",
    "    ready_logprobs = logprobs[is_end_mask]\n",
    "    \n",
    "    ready_list = [(l.cpu().item(), t.cpu().tolist()) for l, t in zip(ready_logprobs, ready_tgt.T)]\n",
    "\n",
    "    not_ready_tgt = tgt[:, ~is_end_mask]\n",
    "    not_ready_logprobs = logprobs[~is_end_mask]\n",
    "    assert not_ready_tgt.shape[1] == not_ready_logprobs.shape[0], (\n",
    "        f\"{not_ready_tgt.shape[1]=} {not_ready_logprobs.shape[0]=}\"\n",
    "    )\n",
    "    return ready_list, not_ready_tgt, not_ready_logprobs\n",
    "\n",
    "\n",
    "sep_ready_tgt(torch.LongTensor([[1, 1], [2, 3]]), torch.tensor([-1., -3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5336cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    if seed < 0:\n",
    "        seed = seed_from_time()\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "set_random_seed(42)\n",
    "\n",
    "class SwipeTransformerRecognizer(pl.LightningModule):\n",
    "    def __init__(self, backbone, learning_rate=1e-4, speed=42):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['backbone'])\n",
    "        self.backbone = backbone\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=0, reduction='mean')\n",
    "#         self.spec_aug = torch.nn.Sequential(\n",
    "#             #T.FrequencyMasking(freq_mask_param=24),\n",
    "#             #T.TimeMasking(time_mask_param=30),\n",
    "#             T.TimeMasking(time_mask_param=24), # last dim masking\n",
    "#         )\n",
    "        set_random_seed(speed)\n",
    "\n",
    "    def forward(self, feats, **kwargs):\n",
    "        # (T, N, E)\n",
    "#         feats = feats.permute(1, 2, 0)\n",
    "#         # (N, E, T)\n",
    "#         feats = self.spec_aug(feats).permute(2, 0, 1)\n",
    "#         if self.training:\n",
    "#             #logging.info(\"Apply specaug\")\n",
    "#             feats = self.spec_aug(feats)\n",
    "        # (T, N, E)\n",
    "        return self.backbone(feats, **kwargs)\n",
    "    \n",
    "    def get_loss(self, batch):\n",
    "        # batch - (Time, Batch, ...)\n",
    "        feats = batch['feats']\n",
    "        # (Time, Batch, num_feats)\n",
    "        tgt = batch['targets'][:-1]\n",
    "        tgt_key_padding_mask = batch['tgt_key_padding_mask'][:, 1:] \n",
    "        # (Batch, Seq-1)\n",
    "        \n",
    "        logits = self.forward(feats=feats, \n",
    "                              tgt=tgt, \n",
    "                              src_key_padding_mask=batch['src_key_padding_mask'], \n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask) \n",
    "        # (Seq-1, Batch, C)\n",
    "        S, N, C = logits.shape\n",
    "        targets = batch['targets'][1:]\n",
    "        # (Seq-1, Batch)\n",
    "        # print(\"loss \", logits.shape, targets.shape)\n",
    "        loss = self.ce_loss(logits.view(-1, C), targets.reshape(-1))\n",
    "        \n",
    "        return loss\n",
    "\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('train_loss', loss, on_epoch=True, prog_bar=True,  batch_size=len(batch['uids']))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('valid_loss', loss, on_step=True,on_epoch=True, prog_bar=True, batch_size=len(batch['uids']))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.get_loss(batch)\n",
    "        self.log('test_loss', loss,  batch_size=len(batch['uids']))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # self.hparams available because we called self.save_hyperparameters()\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
    "        return parser\n",
    "    \n",
    "    def predict_topk(self, dl, tokenizer, topk=4, bos_id=1, eos_id=2, max_out_len=26, device='cuda'):\n",
    "        self.eval()\n",
    "        utt2word= defaultdict(list)\n",
    "        utt2logs = defaultdict(list)\n",
    "        pbar = tqdm(dl)\n",
    "        with torch.no_grad():\n",
    "            for batch in pbar:\n",
    "                batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "                memory = self.backbone.forward_encoder(batch['feats'], \n",
    "                                                  src_key_padding_mask=batch['src_key_padding_mask'])\n",
    "                assert memory.shape[1] == 1, f\"{memory.shape=}\"\n",
    "                # (SrcTime, Batch, E)\n",
    "                tgt = torch.full(size=(1, 1), \n",
    "                                 fill_value=bos_id, \n",
    "                                 dtype=torch.long, \n",
    "                                 device=memory.device)\n",
    "                hyp_logprobs = torch.zeros((1), device=memory.device)\n",
    "                tgt_ready = []\n",
    "                mkpm = batch['src_key_padding_mask']\n",
    "                for l in range(max_out_len):\n",
    "                    #print(f\"{tgt.shape=}\")\n",
    "                    tgt_logits = self.backbone.forward_decoder(tgt, \n",
    "                                                        memory.repeat(1, tgt.shape[1], 1), \n",
    "                                                        memory_key_padding_mask=mkpm.repeat((tgt.shape[1], 1)))\n",
    "                    tgt_logits = tgt_logits.log_softmax(dim=-1)\n",
    "\n",
    "                    new_tgt, logprobs = get_new_tgt(tgt, hyp_logprobs, tgt_logits[-1], topk=topk)\n",
    "                    ready, tgt, hyp_logprobs = sep_ready_tgt(new_tgt, logprobs)\n",
    "                    tgt_ready.extend(ready)\n",
    "                    if len(tgt_ready) >= topk:\n",
    "                        break\n",
    "\n",
    "                uid = batch['uids'][0]\n",
    "                if len(tgt_ready) == 0:\n",
    "                    logging.warning(f\"tgt_ready is 0 for {uid}. {tgt.shape=}. Use all hyps as ready hyps\")\n",
    "                    tgt_ready = [(l.cpu().item(), t.cpu().tolist()) for l, t in zip(hyp_logprobs, tgt.T)]\n",
    "\n",
    "                out_indices = []\n",
    "                for logprob, indices in sorted(tgt_ready, reverse=True):\n",
    "                    joined = tokenizer.decode(indices) #.split()[0]\n",
    "                    utt2word[uid].append(joined)\n",
    "                    utt2logs[uid].append(logprob)\n",
    "                d = '|'+'|'.join(utt2word[uid]) + \"|\"\n",
    "                pbar.set_description(f\"{d}\\t\".ljust(40, '=')[:40], refresh=False)\n",
    "        return utt2word, utt2logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b885d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerWithSinPos(feats_dim=37, num_tokens=500)\n",
    "pl_module = SwipeTransformerRecognizer.load_from_checkpoint('exp/models/transformer_sc/lightning_logs/version_50424998/checkpoints/last.ckpt',backbone=model, map_location='cpu' )\n",
    "#pl_module = SwipeTransformerRecognizer.load_from_checkpoint(\n",
    "#    'exp/models/t_finetune_with_sa/lightning_logs/version_50448424/checkpoints/last-v1.ckpt',\n",
    "#    backbone=model, \n",
    "#    map_location='cpu' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7689c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = FeatsIterableDatasetV2([f\"ark:data_feats/valid/feats.ark\"], \n",
    "                             targets_rspecifier='ark:exp/bpe500/valid-text.int', \n",
    "                                shuffle=False,\n",
    "                               bos_id=1, \n",
    "                               eos_id=2,\n",
    "                               batch_first=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=1, collate_fn=val_ds.collate_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcfc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FeatsIterableDatasetV2([f\"ark:{f}\" for f in sorted(glob(\"data_feats/train/feats.*.ark\"))],\n",
    "                                  targets_rspecifier='ark:exp/bpe500/train-text.int.ark', \n",
    "                                  shuffle=True,\n",
    "                                  bos_id=1, \n",
    "                                  eos_id=2, \n",
    "                                 batch_first=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=24, collate_fn=train_ds.collate_pad, \n",
    "                                                num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a913e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FeatsIterableDatasetV2([f\"ark:{f}\" for f in sorted(glob(\"data_feats/suggestion_accepted/feats.*.ark\"))],\n",
    "                                  targets_rspecifier='ark:exp/bpe500/suggestion_accepted-text.int', \n",
    "                                  shuffle=True,\n",
    "                                  bos_id=1, \n",
    "                                  eos_id=2, \n",
    "                                 batch_first=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=24, collate_fn=train_ds.collate_pad, \n",
    "                                                num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df473f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=6, log_every_n_steps=400, reload_dataloaders_every_n_epochs=1,\n",
    "                    default_root_dir='exp/models/t_finetune_with_sa',\n",
    "                    callbacks=[pl.callbacks.TQDMProgressBar(refresh_rate=100),\n",
    "                              pl.callbacks.ModelCheckpoint(every_n_train_steps=10000,\n",
    "                                                          save_last=True)],\n",
    "                    accumulate_grad_batches=4,\n",
    "                    val_check_interval=20000)\n",
    "                    #check_val_every_n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.test(pl_module, val_dataloader)\n",
    "print(result)\n",
    "# 0.20462335646152496\n",
    "# [{'test_loss': 2.9619081020355225}]\n",
    "# v3.11.11 [{'test_loss': 0.6646422147750854}] /0.27 / 0.23\n",
    "\n",
    "# [{'test_loss': 0.20462335646152496}]\n",
    "# last 11.11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb77a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(pl_module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6fd80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import math\n",
    "tokenizer = spm.SentencePieceProcessor('exp/bpe500/model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028788f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2words, utt2logs = pl_module.cuda().predict_topk(val_dataloader, tokenizer=tokenizer, topk=10, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utt2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d814ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ref_u2w, hyp_u2w):\n",
    "    corr = 0\n",
    "    err = 0\n",
    "    total = len(ref_u2w)\n",
    "    for u, ref in tqdm(ref_u2w.items()):\n",
    "        hyp = hyp_u2w[u].strip('-')\n",
    "        if ref != hyp:\n",
    "            print(ref, hyp)\n",
    "            err +=1\n",
    "        else:\n",
    "            corr +=1\n",
    "    a = corr/total\n",
    "    print(f\"{total=} {corr=} {err=}, accuracy: {a}\")\n",
    "    return a\n",
    "\n",
    "with open('data_feats/valid/text') as f:\n",
    "    valid_ref_u2w = {u:w for u, w in   map(str.split, f.readlines())}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b718b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(valid_ref_u2w, {k:v[0] for k, v in utt2words.items()})\n",
    "# v2.topk2 total=10000 corr=8429 err=1571, accuracy: 0.8429\n",
    "# v2.topk5 total=10000 corr=8434 err=1566, accuracy: 0.8434\n",
    "# v2.topk10 total=10000 corr=8388 err=1612, accuracy: 0.8388\n",
    "# v3.topk10 total=10000 corr=8519 err=1481, accuracy: 0.8519  <--\n",
    "# v3.11.11.topk10 total=10000 corr=8340 err=1660, accuracy: 0.834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/voc.txt') as f:\n",
    "    vocab = frozenset(s for s in map(str.strip, f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv = {}\n",
    "for k, v in utt2words.items():\n",
    "    corr_w = None\n",
    "    for w in v:\n",
    "        if w in vocab:\n",
    "            corr_w = w\n",
    "            break\n",
    "    if corr_w is None: \n",
    "        logging.warning(f\"{k=} doesn't have any vocab hyp. {v=}\")\n",
    "        corr_w = '-'\n",
    "    lv[k] = corr_w\n",
    "accuracy(valid_ref_u2w, lv)\n",
    "# v2.topk10 total=10000 corr=8542 err=1458, accuracy: 0.8542\n",
    "# v3.topk10 total=10000 corr=8665 err=1335, accuracy: 0.8665\n",
    "# v3.11.11.topk10 total=10000 corr=8429 err=1571, accuracy: 0.8429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds =  FeatsIterableDatasetV2([f\"ark:data_feats/test/feats.ark\"], shuffle=False, \n",
    "                                 bos_id=1, \n",
    "                                 eos_id=2, \n",
    "                                 batch_first=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=1, collate_fn=test_ds.collate_pad)\n",
    "#test_u2w = predict(pl_module.backbone, test_dataloader)\n",
    "test_u2w, test_u2l = pl_module.predict_topk(test_dataloader, tokenizer=tokenizer, topk=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5cd6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_vocab(u2w, vocab=vocab):\n",
    "    lv = {}\n",
    "    for k, v in u2w.items():\n",
    "        corr_w = []\n",
    "        for w in v:\n",
    "            if w in vocab:\n",
    "                corr_w.append(w)\n",
    "        if len(corr_w) == 0: \n",
    "            logging.warning(f\"{k=} doesn't have any vocab hyp. {v=}\")\n",
    "            corr_w = ['-']\n",
    "        lv[k] = corr_w\n",
    "    return lv\n",
    "test_lv = limit_vocab(test_u2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247396a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2a9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result = pd.read_csv('exp/models/ctc_trans/lightning_logs/version_50422251/test_submit.v1.csv', sep=',', names=['main', 'second', 'third', 'trash'])\n",
    "baseline_result['uid'] = [f'test-{i}' for i in range(len(baseline_result))]\n",
    "baseline_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7168f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result['predict'] = baseline_result.uid.apply(lambda u: test_lv[u])\n",
    "baseline_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, row in baseline_result.iterrows():\n",
    "    ps = row['predict']\n",
    "    for p in [row['main'], row['second'], row['third'], row['trash']]:\n",
    "        if p not in ps:\n",
    "            ps.append(p)\n",
    "    rows.append(ps[:4])\n",
    "        \n",
    "submission = pd.DataFrame(rows, columns=['main', 'second', 'third', 'trash'])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"exp/models/transformer_sc/lightning_logs/version_50424998/test_submit.v5.csv\", \n",
    "                  sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb125b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
